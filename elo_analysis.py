#!/usr/bin/env python3
"""
IB Mathematics HL IA: Elo Rating Analysis
==========================================

Research Question:
"How does the Elo rating difference between two chess players affect the
probability of winning, and at what rating difference does the advantage
plateau such that further differences no longer significantly impact outcomes?"

This script:
1. Parses real Lichess grandmaster games
2. Extracts Elo ratings and game outcomes
3. Calculates empirical win probabilities
4. Fits a logistic function
5. Computes derivatives to find plateau threshold
6. Performs integration analysis
7. Exports everything to Excel with full calculations shown
"""

import re
import numpy as np
import pandas as pd
from scipy.optimize import curve_fit
from scipy.integrate import quad
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 1: DATA EXTRACTION FROM PGN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_elo_data(pgn_path):
    """
    Extract Elo ratings and game results from PGN file.

    Returns:
        DataFrame with columns: WhiteElo, BlackElo, Result, DeltaR, Outcome
    """
    print("=" * 70)
    print("STEP 1: DATA EXTRACTION")
    print("=" * 70)
    print(f"\nParsing PGN file: {pgn_path}")

    games = []

    with open(pgn_path, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()

    # Pattern to match game headers
    header_pattern = re.compile(r'\[(\w+)\s+"([^"]*)"\]')

    # Split by games (look for [Event tags)
    game_blocks = re.split(r'\n\n(?=\[Event )', content)

    for block in game_blocks:
        headers = {}
        for match in header_pattern.finditer(block):
            key, value = match.groups()
            headers[key] = value

        # Extract required fields
        white_elo = headers.get('WhiteElo', '')
        black_elo = headers.get('BlackElo', '')
        result = headers.get('Result', '')

        # Validate data
        if white_elo and black_elo and result in ['1-0', '0-1', '1/2-1/2']:
            try:
                white_elo = int(white_elo)
                black_elo = int(black_elo)

                # Only include reasonable Elo ranges (exclude provisional ratings)
                if 1000 <= white_elo <= 3500 and 1000 <= black_elo <= 3500:
                    games.append({
                        'WhiteElo': white_elo,
                        'BlackElo': black_elo,
                        'Result': result
                    })
            except ValueError:
                continue

    # Create DataFrame
    df = pd.DataFrame(games)

    if len(df) == 0:
        print("ERROR: No valid games found with Elo ratings")
        return None

    # Calculate rating difference: Î”R = White Elo - Black Elo
    df['DeltaR'] = df['WhiteElo'] - df['BlackElo']

    # Convert result to numeric outcome (from White's perspective)
    # Win = 1, Draw = 0.5, Loss = 0
    def result_to_outcome(result):
        if result == '1-0':
            return 1.0  # White wins
        elif result == '0-1':
            return 0.0  # White loses
        else:
            return 0.5  # Draw

    df['Outcome'] = df['Result'].apply(result_to_outcome)

    print(f"\nData Extraction Complete:")
    print(f"  Total games extracted: {len(df):,}")
    print(f"  White Elo range: {df['WhiteElo'].min()} to {df['WhiteElo'].max()}")
    print(f"  Black Elo range: {df['BlackElo'].min()} to {df['BlackElo'].max()}")
    print(f"  Rating difference range: {df['DeltaR'].min()} to {df['DeltaR'].max()}")
    print(f"\n  Result Distribution:")
    print(f"    White wins (1-0):  {(df['Result'] == '1-0').sum():>6} ({(df['Result'] == '1-0').mean()*100:.1f}%)")
    print(f"    Black wins (0-1):  {(df['Result'] == '0-1').sum():>6} ({(df['Result'] == '0-1').mean()*100:.1f}%)")
    print(f"    Draws (1/2-1/2):   {(df['Result'] == '1/2-1/2').sum():>6} ({(df['Result'] == '1/2-1/2').mean()*100:.1f}%)")

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 2: BIN DATA AND CALCULATE EMPIRICAL PROBABILITIES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calculate_empirical_probabilities(df, bin_size=50):
    """
    Bin rating differences and calculate empirical win probabilities.

    Formula:
        P_win(Î”R) = (Wins + 0.5 Ã— Draws) / Total Games in Bin

    Args:
        df: DataFrame with DeltaR and Outcome columns
        bin_size: Width of each bin (default 50 points)

    Returns:
        DataFrame with binned probabilities
    """
    print("\n" + "=" * 70)
    print("STEP 2: EMPIRICAL PROBABILITY CALCULATION")
    print("=" * 70)

    print(f"\nBinning rating differences with bin size = {bin_size} points")
    print(f"\nFormula: P_win(Î”R) = (Wins + 0.5 Ã— Draws) / Total Games")

    # Create bins
    min_delta = (df['DeltaR'].min() // bin_size) * bin_size
    max_delta = ((df['DeltaR'].max() // bin_size) + 1) * bin_size
    bins = np.arange(min_delta, max_delta + bin_size, bin_size)

    # Assign each game to a bin
    df['Bin'] = pd.cut(df['DeltaR'], bins=bins, labels=bins[:-1] + bin_size/2)

    # Calculate statistics for each bin
    binned_data = []

    for bin_center in sorted(df['Bin'].dropna().unique()):
        bin_df = df[df['Bin'] == bin_center]

        n_games = len(bin_df)
        n_wins = (bin_df['Result'] == '1-0').sum()
        n_losses = (bin_df['Result'] == '0-1').sum()
        n_draws = (bin_df['Result'] == '1/2-1/2').sum()

        # Empirical probability
        p_win = bin_df['Outcome'].mean()

        binned_data.append({
            'DeltaR': float(bin_center),
            'N_Games': n_games,
            'N_Wins': n_wins,
            'N_Losses': n_losses,
            'N_Draws': n_draws,
            'P_win_empirical': p_win
        })

    binned_df = pd.DataFrame(binned_data)

    # Filter bins with at least 10 games for statistical significance
    min_games = 10
    binned_df = binned_df[binned_df['N_Games'] >= min_games].reset_index(drop=True)

    print(f"\nEmpirical Probability Calculation:")
    print(f"  Total bins created: {len(binned_df)}")
    print(f"  Minimum games per bin: {min_games}")
    print(f"  Î”R range used: {binned_df['DeltaR'].min():.0f} to {binned_df['DeltaR'].max():.0f}")

    print(f"\n  Sample Calculations:")
    print(f"  {'Î”R':>8} {'Games':>8} {'Wins':>6} {'Draws':>6} {'Losses':>6} {'P_win':>10}")
    print(f"  {'-'*8} {'-'*8} {'-'*6} {'-'*6} {'-'*6} {'-'*10}")

    # Show a few sample rows
    sample_indices = [0, len(binned_df)//4, len(binned_df)//2, 3*len(binned_df)//4, len(binned_df)-1]
    for idx in sample_indices:
        if idx < len(binned_df):
            row = binned_df.iloc[idx]
            print(f"  {row['DeltaR']:>8.0f} {row['N_Games']:>8} {row['N_Wins']:>6} "
                  f"{row['N_Draws']:>6} {row['N_Losses']:>6} {row['P_win_empirical']:>10.4f}")

    return binned_df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 3: LOGISTIC FUNCTION FITTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def logistic_function(x, k, x0):
    """
    Logistic function for modeling win probability.

    P(Î”R) = 1 / (1 + e^(-k(Î”R - xâ‚€)))

    Parameters:
        x: Rating difference (Î”R)
        k: Slope parameter (determines steepness)
        x0: Midpoint (Î”R where P = 0.5)

    Returns:
        Probability of winning
    """
    return 1 / (1 + np.exp(-k * (x - x0)))


def fit_logistic_model(binned_df):
    """
    Fit logistic function to empirical data using least squares.

    Returns:
        k, x0: Fitted parameters
        r_squared: Goodness of fit
        residuals: Difference between predicted and actual
    """
    print("\n" + "=" * 70)
    print("STEP 3: LOGISTIC FUNCTION FITTING")
    print("=" * 70)

    print(f"\nModel: P(Î”R) = 1 / (1 + e^(-k(Î”R - xâ‚€)))")
    print(f"\nwhere:")
    print(f"  k  = slope parameter (steepness of curve)")
    print(f"  xâ‚€ = midpoint (Î”R where probability = 0.5)")

    # Prepare data
    x_data = binned_df['DeltaR'].values
    y_data = binned_df['P_win_empirical'].values
    weights = np.sqrt(binned_df['N_Games'].values)  # Weight by sample size

    # Initial guess
    p0 = [0.004, 0]  # k around 1/250, x0 around 0

    # Fit curve
    try:
        params, covariance = curve_fit(
            logistic_function, x_data, y_data,
            p0=p0,
            sigma=1/weights,
            maxfev=10000
        )
        k, x0 = params

        # Calculate predictions
        y_pred = logistic_function(x_data, k, x0)

        # Calculate RÂ²
        ss_res = np.sum((y_data - y_pred) ** 2)
        ss_tot = np.sum((y_data - np.mean(y_data)) ** 2)
        r_squared = 1 - (ss_res / ss_tot)

        # Residuals
        residuals = y_data - y_pred

        print(f"\nâ”Œ{'â”€'*50}â”")
        print(f"â”‚{'FITTED PARAMETERS':^50}â”‚")
        print(f"â”œ{'â”€'*50}â”¤")
        print(f"â”‚  k (slope)     = {k:>20.6f}             â”‚")
        print(f"â”‚  xâ‚€ (midpoint) = {x0:>20.4f}             â”‚")
        print(f"â”‚  RÂ² (fit)      = {r_squared:>20.4f}             â”‚")
        print(f"â””{'â”€'*50}â”˜")

        print(f"\nInterpretation:")
        print(f"  â€¢ The fitted logistic function is:")
        print(f"    P(Î”R) = 1 / (1 + e^({-k:.6f} Ã— (Î”R - {x0:.2f})))")
        print(f"  â€¢ At Î”R = 0 (equal ratings), P(win) = {logistic_function(0, k, x0):.4f}")
        print(f"  â€¢ At Î”R = 100, P(win) = {logistic_function(100, k, x0):.4f}")
        print(f"  â€¢ At Î”R = 200, P(win) = {logistic_function(200, k, x0):.4f}")
        print(f"  â€¢ At Î”R = 400, P(win) = {logistic_function(400, k, x0):.4f}")

        return k, x0, r_squared, residuals, y_pred

    except Exception as e:
        print(f"Error fitting logistic function: {e}")
        return None, None, None, None, None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 4: DERIVATIVE ANALYSIS (CALCULUS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def logistic_derivative(x, k, x0):
    """
    First derivative of logistic function.

    dP/dÎ”R = k Ã— e^(-k(Î”R - xâ‚€)) / (1 + e^(-k(Î”R - xâ‚€)))Â²

    This represents the SENSITIVITY of probability to rating changes.
    Higher derivative = more sensitive to rating difference.
    """
    exp_term = np.exp(-k * (x - x0))
    return k * exp_term / ((1 + exp_term) ** 2)


def logistic_second_derivative(x, k, x0):
    """
    Second derivative of logistic function.

    dÂ²P/dÎ”RÂ² = -kÂ² Ã— e^(-k(Î”R - xâ‚€)) Ã— (1 - e^(-k(Î”R - xâ‚€))) / (1 + e^(-k(Î”R - xâ‚€)))Â³

    Shows the inflection point where probability sensitivity changes fastest.
    """
    exp_term = np.exp(-k * (x - x0))
    numerator = -k**2 * exp_term * (1 - exp_term)
    denominator = (1 + exp_term) ** 3
    return numerator / denominator


def find_plateau_threshold(k, x0, epsilon=0.0001):
    """
    Find the rating difference beyond which further differences don't matter.

    Solve for Î”R* where: dP/dÎ”R < Îµ

    At the plateau, the derivative approaches zero, meaning changes in
    rating difference have negligible effect on win probability.

    Args:
        k, x0: Logistic parameters
        epsilon: Threshold for "negligible" derivative

    Returns:
        delta_r_star: Plateau threshold (both positive and negative)
    """
    # Maximum derivative occurs at x0
    max_derivative = k / 4  # This is the value at x = x0

    # Find where derivative drops below epsilon
    # Using numerical search
    for delta_r in range(0, 1000, 1):
        deriv = logistic_derivative(x0 + delta_r, k, x0)
        if deriv < epsilon:
            return delta_r

    return 500  # Default if not found


def derivative_analysis(k, x0, binned_df):
    """
    Perform derivative analysis to find plateau threshold.
    """
    print("\n" + "=" * 70)
    print("STEP 4: DERIVATIVE ANALYSIS (CALCULUS)")
    print("=" * 70)

    print(f"\nFirst Derivative Formula:")
    print(f"  dP/dÎ”R = k Ã— e^(-k(Î”R - xâ‚€)) / (1 + e^(-k(Î”R - xâ‚€)))Â²")
    print(f"\nThis represents the SENSITIVITY of win probability to rating changes.")

    # Calculate derivatives at key points
    delta_r_values = np.arange(-400, 401, 50)

    print(f"\n  {'Î”R':>8} {'P(Î”R)':>10} {'dP/dÎ”R':>12} {'dÂ²P/dÎ”RÂ²':>14}")
    print(f"  {'-'*8} {'-'*10} {'-'*12} {'-'*14}")

    derivative_data = []

    for delta_r in delta_r_values:
        p = logistic_function(delta_r, k, x0)
        dp = logistic_derivative(delta_r, k, x0)
        d2p = logistic_second_derivative(delta_r, k, x0)

        derivative_data.append({
            'DeltaR': delta_r,
            'P_win': p,
            'dP_dDeltaR': dp,
            'd2P_dDeltaR2': d2p
        })

        if delta_r in [-400, -200, -100, 0, 100, 200, 400]:
            print(f"  {delta_r:>8} {p:>10.4f} {dp:>12.6f} {d2p:>14.8f}")

    derivative_df = pd.DataFrame(derivative_data)

    # Find plateau threshold
    epsilon_values = [0.001, 0.0005, 0.0001]

    print(f"\nâ”Œ{'â”€'*60}â”")
    print(f"â”‚{'PLATEAU THRESHOLD ANALYSIS':^60}â”‚")
    print(f"â”œ{'â”€'*60}â”¤")
    print(f"â”‚ The plateau is where dP/dÎ”R becomes negligibly small,        â”‚")
    print(f"â”‚ meaning further rating differences don't significantly       â”‚")
    print(f"â”‚ impact the probability of winning.                           â”‚")
    print(f"â”œ{'â”€'*60}â”¤")

    plateau_thresholds = {}
    for eps in epsilon_values:
        threshold = find_plateau_threshold(k, x0, eps)
        plateau_thresholds[eps] = threshold
        prob_at_threshold = logistic_function(x0 + threshold, k, x0)
        print(f"â”‚ Îµ = {eps:<8} â†’ Î”R* = {threshold:>4} (P_win = {prob_at_threshold:.4f})            â”‚")

    print(f"â””{'â”€'*60}â”˜")

    # Use middle epsilon as primary threshold
    delta_r_star = plateau_thresholds[0.0005]

    print(f"\nğŸ“ Mathematical Interpretation:")
    print(f"   At Î”R* = Â±{delta_r_star} rating points:")
    print(f"   â€¢ The derivative dP/dÎ”R â‰ˆ 0.0005")
    print(f"   â€¢ Win probability has essentially plateaued")
    print(f"   â€¢ P(Î”R = +{delta_r_star}) = {logistic_function(x0 + delta_r_star, k, x0):.4f}")
    print(f"   â€¢ P(Î”R = -{delta_r_star}) = {logistic_function(x0 - delta_r_star, k, x0):.4f}")
    print(f"\n   Beyond this threshold, rating differences have")
    print(f"   diminishing returns on expected outcomes.")

    return derivative_df, delta_r_star


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 5: INTEGRATION ANALYSIS (HL MATH)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def integration_analysis(k, x0, delta_range=(-400, 400)):
    """
    Compute average winning probability across rating spectrum using integration.

    Average P_win = (1/Î”R_range) Ã— âˆ« P(Î”R) dÎ”R

    This shows the overall impact of rating differences.
    """
    print("\n" + "=" * 70)
    print("STEP 5: INTEGRATION ANALYSIS (HL CALCULUS)")
    print("=" * 70)

    print(f"\nComputing average win probability across rating spectrum:")
    print(f"  Range: Î”R âˆˆ [{delta_range[0]}, {delta_range[1]}]")
    print(f"\n  Formula: Average P_win = (1/(b-a)) Ã— âˆ«[a,b] P(Î”R) dÎ”R")

    # Define function to integrate
    def p_win(x):
        return logistic_function(x, k, x0)

    # Numerical integration
    integral, error = quad(p_win, delta_range[0], delta_range[1])

    # Average probability
    range_width = delta_range[1] - delta_range[0]
    average_p = integral / range_width

    print(f"\nâ”Œ{'â”€'*60}â”")
    print(f"â”‚{'INTEGRATION RESULTS':^60}â”‚")
    print(f"â”œ{'â”€'*60}â”¤")
    print(f"â”‚ âˆ« P(Î”R) dÎ”R from {delta_range[0]} to {delta_range[1]}                           â”‚")
    print(f"â”‚                                                            â”‚")
    print(f"â”‚ Integral value = {integral:>10.4f}                               â”‚")
    print(f"â”‚ Range width    = {range_width:>10.0f}                               â”‚")
    print(f"â”‚ Average P_win  = {average_p:>10.4f}                               â”‚")
    print(f"â””{'â”€'*60}â”˜")

    # Calculate area by segments
    print(f"\n  Breakdown by Î”R segments:")
    print(f"  {'Segment':>20} {'âˆ«P dÎ”R':>12} {'Avg P':>10}")
    print(f"  {'-'*20} {'-'*12} {'-'*10}")

    segments = [(-400, -200), (-200, 0), (0, 200), (200, 400)]
    segment_data = []

    for a, b in segments:
        seg_integral, _ = quad(p_win, a, b)
        seg_avg = seg_integral / (b - a)
        segment_data.append({
            'Segment': f"[{a}, {b}]",
            'Integral': seg_integral,
            'Average_P': seg_avg
        })
        print(f"  {f'[{a}, {b}]':>20} {seg_integral:>12.4f} {seg_avg:>10.4f}")

    segment_df = pd.DataFrame(segment_data)

    print(f"\nğŸ“ Interpretation:")
    print(f"   The integral represents the 'total accumulated probability'")
    print(f"   across the rating difference spectrum.")
    print(f"   Average P_win = {average_p:.4f} â‰ˆ {average_p*100:.1f}% across all Î”R values")

    # Analytical antiderivative (for reference)
    print(f"\n   Analytical Antiderivative:")
    print(f"   âˆ« 1/(1+e^(-k(x-xâ‚€))) dx = x + (1/k)ln(1+e^(-k(x-xâ‚€))) + C")

    return integral, average_p, segment_df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 6: CREATE EXCEL SPREADSHEET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_excel_workbook(df, binned_df, k, x0, r_squared, derivative_df,
                          delta_r_star, integral, average_p, segment_df):
    """
    Create comprehensive Excel workbook with all analysis.
    """
    print("\n" + "=" * 70)
    print("STEP 6: CREATING EXCEL SPREADSHEET")
    print("=" * 70)

    output_path = Path("results/elo_analysis.xlsx")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
        workbook = writer.book

        # Formats
        header_format = workbook.add_format({
            'bold': True, 'bg_color': '#4472C4', 'font_color': 'white',
            'border': 1, 'align': 'center'
        })
        number_format = workbook.add_format({'num_format': '0.0000', 'border': 1})
        int_format = workbook.add_format({'num_format': '0', 'border': 1})
        percent_format = workbook.add_format({'num_format': '0.00%', 'border': 1})
        title_format = workbook.add_format({
            'bold': True, 'font_size': 14, 'bg_color': '#2E75B6', 'font_color': 'white'
        })
        formula_format = workbook.add_format({
            'italic': True, 'font_color': '#7030A0', 'font_size': 11
        })

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SHEET 1: RAW DATA
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        raw_sample = df.head(500)  # First 500 games
        raw_sample.to_excel(writer, sheet_name='1_Raw_Data', index=False, startrow=2)

        ws1 = writer.sheets['1_Raw_Data']
        ws1.write('A1', 'RAW GAME DATA (Sample of first 500 games)', title_format)
        ws1.write('A2', f'Total games in dataset: {len(df)}', formula_format)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SHEET 2: BINNED PROBABILITIES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        binned_df.to_excel(writer, sheet_name='2_Empirical_Probabilities', index=False, startrow=4)

        ws2 = writer.sheets['2_Empirical_Probabilities']
        ws2.write('A1', 'EMPIRICAL PROBABILITY CALCULATION', title_format)
        ws2.write('A2', 'Formula: P_win(Î”R) = (Wins + 0.5 Ã— Draws) / Total Games', formula_format)
        ws2.write('A3', f'Bin size: 50 rating points | Minimum games per bin: 10', formula_format)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SHEET 3: LOGISTIC FIT
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ws3 = workbook.add_worksheet('3_Logistic_Model')

        ws3.write('A1', 'LOGISTIC FUNCTION MODEL', title_format)
        ws3.merge_range('A1:F1', 'LOGISTIC FUNCTION MODEL', title_format)

        ws3.write('A3', 'Model Formula:', header_format)
        ws3.merge_range('B3:F3', 'P(Î”R) = 1 / (1 + e^(-k(Î”R - xâ‚€)))', formula_format)

        ws3.write('A5', 'FITTED PARAMETERS', header_format)
        ws3.merge_range('A5:B5', 'FITTED PARAMETERS', header_format)

        ws3.write('A6', 'k (slope)')
        ws3.write('B6', k, number_format)
        ws3.write('C6', 'â† Determines steepness of curve')

        ws3.write('A7', 'xâ‚€ (midpoint)')
        ws3.write('B7', x0, number_format)
        ws3.write('C7', 'â† Î”R where P = 0.5')

        ws3.write('A8', 'RÂ² (goodness of fit)')
        ws3.write('B8', r_squared, number_format)
        ws3.write('C8', 'â† Higher is better (max 1.0)')

        # Predictions table
        ws3.write('A11', 'PREDICTIONS FROM MODEL', header_format)
        ws3.merge_range('A11:D11', 'PREDICTIONS FROM MODEL', header_format)

        ws3.write('A12', 'Î”R', header_format)
        ws3.write('B12', 'P(win) Predicted', header_format)
        ws3.write('C12', 'P(win) Empirical', header_format)
        ws3.write('D12', 'Residual', header_format)

        for i, (_, row) in enumerate(binned_df.iterrows()):
            ws3.write(12 + i + 1, 0, row['DeltaR'], int_format)
            ws3.write(12 + i + 1, 1, logistic_function(row['DeltaR'], k, x0), number_format)
            ws3.write(12 + i + 1, 2, row['P_win_empirical'], number_format)
            ws3.write(12 + i + 1, 3, row['P_win_empirical'] - logistic_function(row['DeltaR'], k, x0), number_format)

        ws3.set_column('A:A', 15)
        ws3.set_column('B:D', 18)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SHEET 4: DERIVATIVE ANALYSIS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ws4 = workbook.add_worksheet('4_Derivative_Analysis')

        ws4.write('A1', 'DERIVATIVE ANALYSIS (CALCULUS)', title_format)
        ws4.merge_range('A1:E1', 'DERIVATIVE ANALYSIS (CALCULUS)', title_format)

        ws4.write('A3', 'First Derivative:', header_format)
        ws4.merge_range('B3:E3', 'dP/dÎ”R = k Ã— e^(-k(Î”R - xâ‚€)) / (1 + e^(-k(Î”R - xâ‚€)))Â²', formula_format)

        ws4.write('A4', 'Interpretation:', header_format)
        ws4.merge_range('B4:E4', 'Sensitivity of win probability to rating changes', formula_format)

        ws4.write('A6', 'PLATEAU THRESHOLD', header_format)
        ws4.merge_range('A6:B6', 'PLATEAU THRESHOLD', header_format)

        ws4.write('A7', 'Î”R* (Îµ=0.0005)')
        ws4.write('B7', delta_r_star, int_format)
        ws4.write('C7', f'Rating difference beyond which outcomes plateau')

        ws4.write('A8', 'P(win) at +Î”R*')
        ws4.write('B8', logistic_function(x0 + delta_r_star, k, x0), number_format)

        ws4.write('A9', 'P(win) at -Î”R*')
        ws4.write('B9', logistic_function(x0 - delta_r_star, k, x0), number_format)

        # Derivative table
        derivative_df.to_excel(writer, sheet_name='4_Derivative_Analysis', index=False, startrow=11)

        ws4.set_column('A:A', 15)
        ws4.set_column('B:D', 18)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SHEET 5: INTEGRATION ANALYSIS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ws5 = workbook.add_worksheet('5_Integration_Analysis')

        ws5.write('A1', 'INTEGRATION ANALYSIS (HL CALCULUS)', title_format)
        ws5.merge_range('A1:E1', 'INTEGRATION ANALYSIS (HL CALCULUS)', title_format)

        ws5.write('A3', 'Formula:', header_format)
        ws5.merge_range('B3:E3', 'Average P_win = (1/(b-a)) Ã— âˆ«[a,b] P(Î”R) dÎ”R', formula_format)

        ws5.write('A5', 'INTEGRATION RESULTS', header_format)
        ws5.merge_range('A5:B5', 'INTEGRATION RESULTS', header_format)

        ws5.write('A6', 'Integration Range')
        ws5.write('B6', '[-400, 400]')

        ws5.write('A7', 'âˆ« P(Î”R) dÎ”R')
        ws5.write('B7', integral, number_format)

        ws5.write('A8', 'Range Width')
        ws5.write('B8', 800, int_format)

        ws5.write('A9', 'Average P_win')
        ws5.write('B9', average_p, number_format)

        ws5.write('A11', 'Segment Breakdown:', header_format)
        segment_df.to_excel(writer, sheet_name='5_Integration_Analysis', index=False, startrow=12)

        ws5.set_column('A:A', 20)
        ws5.set_column('B:C', 15)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SHEET 6: SUMMARY
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ws6 = workbook.add_worksheet('6_Summary')

        ws6.merge_range('A1:F1', 'IB MATHEMATICS HL IA: ELO RATING ANALYSIS SUMMARY', title_format)

        ws6.write('A3', 'Research Question:', header_format)
        ws6.merge_range('B3:F3', '"How does the Elo rating difference between two chess players affect '
                       'the probability of winning, and at what rating difference does the advantage '
                       'plateau?"', formula_format)

        ws6.write('A5', 'DATA SUMMARY', header_format)
        ws6.write('A6', 'Total Games Analyzed')
        ws6.write('B6', len(df), int_format)

        ws6.write('A7', 'White Win Rate')
        ws6.write('B7', (df['Result'] == '1-0').mean(), percent_format)

        ws6.write('A8', 'Black Win Rate')
        ws6.write('B8', (df['Result'] == '0-1').mean(), percent_format)

        ws6.write('A9', 'Draw Rate')
        ws6.write('B9', (df['Result'] == '1/2-1/2').mean(), percent_format)

        ws6.write('A11', 'KEY FINDINGS', header_format)

        ws6.write('A12', '1. Logistic Model')
        ws6.write('B12', f'P(Î”R) = 1 / (1 + e^({-k:.6f}(Î”R - {x0:.2f})))')

        ws6.write('A13', '2. Model Fit (RÂ²)')
        ws6.write('B13', r_squared, number_format)

        ws6.write('A14', '3. Plateau Threshold')
        ws6.write('B14', f'Â±{delta_r_star} rating points')

        ws6.write('A15', '4. At Equal Ratings')
        ws6.write('B15', f'P(win) = {logistic_function(0, k, x0):.4f}')

        ws6.write('A16', '5. Average P_win')
        ws6.write('B16', average_p, number_format)

        ws6.write('A18', 'MATHEMATICAL CONCEPTS USED', header_format)
        ws6.write('A19', 'â€¢ Probability (empirical vs theoretical)')
        ws6.write('A20', 'â€¢ Curve fitting (logistic regression)')
        ws6.write('A21', 'â€¢ Calculus: First and second derivatives')
        ws6.write('A22', 'â€¢ Calculus: Definite integration')
        ws6.write('A23', 'â€¢ Sensitivity analysis and thresholds')

        ws6.set_column('A:A', 25)
        ws6.set_column('B:F', 15)

    print(f"\n  Excel workbook saved to: {output_path}")
    return str(output_path)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 7: CREATE VISUALIZATIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_visualizations(binned_df, k, x0, derivative_df, delta_r_star, r_squared):
    """Create publication-quality visualizations."""
    print("\n" + "=" * 70)
    print("STEP 7: CREATING VISUALIZATIONS")
    print("=" * 70)

    output_dir = Path("visualizations")
    output_dir.mkdir(exist_ok=True)

    plt.style.use('seaborn-v0_8-whitegrid')

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Figure 1: Logistic Fit with Empirical Data
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig, ax = plt.subplots(figsize=(12, 8))

    # Plot empirical data
    scatter = ax.scatter(binned_df['DeltaR'], binned_df['P_win_empirical'],
                        s=binned_df['N_Games']/2, alpha=0.6, c='#3498db',
                        label='Empirical Data (size âˆ sample size)', edgecolors='navy')

    # Plot fitted logistic curve
    x_smooth = np.linspace(-500, 500, 1000)
    y_smooth = logistic_function(x_smooth, k, x0)
    ax.plot(x_smooth, y_smooth, 'r-', linewidth=2.5,
            label=f'Logistic Fit: P = 1/(1+e^({-k:.5f}(Î”R-{x0:.1f})))')

    # Reference lines
    ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='P = 0.5')
    ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5, label='Î”R = 0')

    ax.set_xlabel('Rating Difference (Î”R = White Elo - Black Elo)', fontsize=12)
    ax.set_ylabel('Probability White Wins', fontsize=12)
    ax.set_title('Elo Rating Difference vs Win Probability\nLogistic Model Fit', fontsize=14)
    ax.legend(loc='lower right', fontsize=10)
    ax.set_xlim(-500, 500)
    ax.set_ylim(0, 1)
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_dir / 'elo_logistic_fit.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: visualizations/elo_logistic_fit.png")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Figure 2: Derivative Analysis
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig, axes = plt.subplots(2, 1, figsize=(12, 10))

    # First derivative
    ax1 = axes[0]
    x_range = np.linspace(-500, 500, 1000)
    y_deriv = logistic_derivative(x_range, k, x0)

    ax1.plot(x_range, y_deriv, 'g-', linewidth=2, label='dP/dÎ”R')
    ax1.axhline(y=0.0005, color='red', linestyle='--', alpha=0.7, label='Threshold Îµ = 0.0005')
    ax1.axvline(x=delta_r_star, color='purple', linestyle=':', alpha=0.7,
                label=f'Plateau: Î”R* = {delta_r_star}')
    ax1.axvline(x=-delta_r_star, color='purple', linestyle=':', alpha=0.7)

    ax1.fill_between(x_range, y_deriv, where=(np.abs(x_range) > delta_r_star),
                     alpha=0.3, color='yellow', label='Plateau region')

    ax1.set_xlabel('Rating Difference (Î”R)', fontsize=11)
    ax1.set_ylabel('dP/dÎ”R', fontsize=11)
    ax1.set_title('First Derivative: Sensitivity of Win Probability to Rating Difference', fontsize=12)
    ax1.legend(loc='upper right')
    ax1.grid(True, alpha=0.3)

    # Second derivative
    ax2 = axes[1]
    y_deriv2 = logistic_second_derivative(x_range, k, x0)

    ax2.plot(x_range, y_deriv2, 'b-', linewidth=2, label='dÂ²P/dÎ”RÂ²')
    ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.5)
    ax2.axvline(x=x0, color='red', linestyle='--', alpha=0.7, label=f'Inflection point: Î”R = {x0:.1f}')

    ax2.set_xlabel('Rating Difference (Î”R)', fontsize=11)
    ax2.set_ylabel('dÂ²P/dÎ”RÂ²', fontsize=11)
    ax2.set_title('Second Derivative: Rate of Change of Sensitivity', fontsize=12)
    ax2.legend(loc='upper right')
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_dir / 'elo_derivative_analysis.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: visualizations/elo_derivative_analysis.png")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Figure 3: Integration Visualization
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig, ax = plt.subplots(figsize=(12, 8))

    x_range = np.linspace(-400, 400, 1000)
    y_prob = logistic_function(x_range, k, x0)

    ax.plot(x_range, y_prob, 'b-', linewidth=2, label='P(Î”R)')
    ax.fill_between(x_range, y_prob, alpha=0.3, color='blue',
                    label='âˆ«P(Î”R)dÎ”R (area under curve)')

    ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
    ax.set_xlabel('Rating Difference (Î”R)', fontsize=12)
    ax.set_ylabel('P(win)', fontsize=12)
    ax.set_title('Integration: Area Under the Win Probability Curve\n'
                 'âˆ«P(Î”R)dÎ”R represents total accumulated probability', fontsize=14)
    ax.legend(loc='lower right')
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_dir / 'elo_integration.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: visualizations/elo_integration.png")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Figure 4: Summary Dashboard
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))

    # Top left: Logistic fit
    ax1 = axes[0, 0]
    ax1.scatter(binned_df['DeltaR'], binned_df['P_win_empirical'],
               s=30, alpha=0.6, c='#3498db', edgecolors='navy')
    x_smooth = np.linspace(-500, 500, 500)
    ax1.plot(x_smooth, logistic_function(x_smooth, k, x0), 'r-', linewidth=2)
    ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
    ax1.set_xlabel('Î”R')
    ax1.set_ylabel('P(win)')
    ax1.set_title(f'Logistic Model Fit (RÂ² = {r_squared:.4f})')
    ax1.set_xlim(-500, 500)
    ax1.grid(True, alpha=0.3)

    # Top right: Derivative
    ax2 = axes[0, 1]
    ax2.plot(x_smooth, logistic_derivative(x_smooth, k, x0), 'g-', linewidth=2)
    ax2.axhline(y=0.0005, color='red', linestyle='--', alpha=0.7)
    ax2.axvline(x=delta_r_star, color='purple', linestyle=':', alpha=0.7)
    ax2.axvline(x=-delta_r_star, color='purple', linestyle=':', alpha=0.7)
    ax2.set_xlabel('Î”R')
    ax2.set_ylabel('dP/dÎ”R')
    ax2.set_title(f'First Derivative (Plateau at Î”R* = Â±{delta_r_star})')
    ax2.grid(True, alpha=0.3)

    # Bottom left: Key values table
    ax3 = axes[1, 0]
    ax3.axis('off')

    table_data = [
        ['Parameter', 'Value'],
        ['k (slope)', f'{k:.6f}'],
        ['xâ‚€ (midpoint)', f'{x0:.2f}'],
        ['RÂ²', f'{r_squared:.4f}'],
        ['Plateau Î”R*', f'Â±{delta_r_star}'],
        ['P(Î”R=0)', f'{logistic_function(0, k, x0):.4f}'],
        ['P(Î”R=100)', f'{logistic_function(100, k, x0):.4f}'],
        ['P(Î”R=200)', f'{logistic_function(200, k, x0):.4f}'],
        ['P(Î”R=400)', f'{logistic_function(400, k, x0):.4f}'],
    ]

    table = ax3.table(cellText=table_data, loc='center', cellLoc='center',
                     colWidths=[0.4, 0.4])
    table.auto_set_font_size(False)
    table.set_fontsize(11)
    table.scale(1.2, 1.8)

    # Header formatting
    for i in range(2):
        table[(0, i)].set_facecolor('#4472C4')
        table[(0, i)].set_text_props(color='white', fontweight='bold')

    ax3.set_title('Key Results', fontsize=12, pad=20)

    # Bottom right: Probability at key points
    ax4 = axes[1, 1]
    delta_r_points = [-400, -200, -100, 0, 100, 200, 400]
    probs = [logistic_function(dr, k, x0) for dr in delta_r_points]
    colors = ['#e74c3c' if p < 0.5 else '#27ae60' for p in probs]

    bars = ax4.bar([str(dr) for dr in delta_r_points], probs, color=colors, edgecolor='black')
    ax4.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)
    ax4.set_xlabel('Rating Difference (Î”R)')
    ax4.set_ylabel('P(White wins)')
    ax4.set_title('Win Probability at Key Rating Differences')

    for bar, prob in zip(bars, probs):
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                f'{prob:.3f}', ha='center', fontsize=9)

    ax4.set_ylim(0, 1.1)

    plt.suptitle('IB Math HL IA: Elo Rating Analysis Summary', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.subplots_adjust(top=0.93)
    plt.savefig(output_dir / 'elo_summary_dashboard.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: visualizations/elo_summary_dashboard.png")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN FUNCTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Run the complete Elo rating analysis."""

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘          IB MATHEMATICS HL IA: ELO RATING ANALYSIS                           â•‘
â•‘          â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                       â•‘
â•‘                                                                              â•‘
â•‘  Research Question:                                                          â•‘
â•‘  "How does the Elo rating difference between two chess players affect       â•‘
â•‘   the probability of winning, and at what rating difference does the        â•‘
â•‘   advantage plateau such that further differences no longer significantly   â•‘
â•‘   impact outcomes?"                                                          â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # Check for data file
    data_file = Path("data/grandmaster_games.pgn")
    if not data_file.exists():
        print("ERROR: Data file not found at data/grandmaster_games.pgn")
        print("Please run main.py first to download the data.")
        return

    # STEP 1: Extract Elo data
    df = extract_elo_data(str(data_file))
    if df is None or len(df) == 0:
        return

    # STEP 2: Calculate empirical probabilities
    binned_df = calculate_empirical_probabilities(df, bin_size=50)

    # STEP 3: Fit logistic model
    k, x0, r_squared, residuals, y_pred = fit_logistic_model(binned_df)
    if k is None:
        return

    # STEP 4: Derivative analysis
    derivative_df, delta_r_star = derivative_analysis(k, x0, binned_df)

    # STEP 5: Integration analysis
    integral, average_p, segment_df = integration_analysis(k, x0)

    # STEP 6: Create Excel workbook
    excel_path = create_excel_workbook(
        df, binned_df, k, x0, r_squared, derivative_df,
        delta_r_star, integral, average_p, segment_df
    )

    # STEP 7: Create visualizations
    create_visualizations(binned_df, k, x0, derivative_df, delta_r_star, r_squared)

    # Final Summary
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                           ANALYSIS COMPLETE                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  DATA SUMMARY:                                                               â•‘
â•‘    â€¢ Total games analyzed: {len(df):>7,}                                       â•‘
â•‘    â€¢ Elo range: {df['WhiteElo'].min()}-{df['WhiteElo'].max()}                                           â•‘
â•‘                                                                              â•‘
â•‘  LOGISTIC MODEL:                                                             â•‘
â•‘    â€¢ P(Î”R) = 1 / (1 + e^({-k:.6f}(Î”R - {x0:.1f})))                        â•‘
â•‘    â€¢ RÂ² = {r_squared:.4f} (goodness of fit)                                    â•‘
â•‘                                                                              â•‘
â•‘  KEY FINDINGS:                                                               â•‘
â•‘    â€¢ At equal ratings (Î”R=0): P(win) = {logistic_function(0, k, x0):.4f}                     â•‘
â•‘    â€¢ At Î”R=+100: P(win) = {logistic_function(100, k, x0):.4f}                                â•‘
â•‘    â€¢ At Î”R=+200: P(win) = {logistic_function(200, k, x0):.4f}                                â•‘
â•‘    â€¢ Plateau threshold: Î”R* = Â±{delta_r_star} rating points                    â•‘
â•‘                                                                              â•‘
â•‘  CALCULUS RESULTS:                                                           â•‘
â•‘    â€¢ Derivative analysis shows sensitivity drops below Îµ at Î”R*             â•‘
â•‘    â€¢ Integration gives average P_win = {average_p:.4f} across spectrum          â•‘
â•‘                                                                              â•‘
â•‘  OUTPUT FILES:                                                               â•‘
â•‘    â€¢ results/elo_analysis.xlsx - Complete Excel workbook                     â•‘
â•‘    â€¢ visualizations/elo_logistic_fit.png                                     â•‘
â•‘    â€¢ visualizations/elo_derivative_analysis.png                              â•‘
â•‘    â€¢ visualizations/elo_integration.png                                      â•‘
â•‘    â€¢ visualizations/elo_summary_dashboard.png                                â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


if __name__ == "__main__":
    main()
